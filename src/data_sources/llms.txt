# Data Sources Library

> Multi-source data collection system for comprehensive prospect research with external API integrations and intelligent orchestration.

This library provides a comprehensive data collection framework that integrates with multiple external data sources to gather rich company information. It includes dedicated modules for major data providers and an intelligent manager for orchestrating parallel data collection.

## Core Components

- [Manager](manager.py): Orchestrates data collection from multiple sources with error handling and performance optimization
- [Apollo Source](apollo_source.py): Apollo.io API integration for company enrichment and contact data
- [Serper Source](serper_source.py): Serper API integration for web search and research intelligence
- [LinkedIn Source](linkedin_source.py): LinkedIn company research using Firecrawl and authenticated browsing
- [Job Boards Source](job_boards_source.py): Multi-platform job board data collection (Seek, Indeed, Glassdoor, LinkedIn)
- [News Source](news_source.py): News and media monitoring from Google News, Bing News, and specialized APIs
- [Government Source](government_source.py): Official registry data from SEC, Companies House, ASIC, and international registries
- [Playwright Source](playwright_source.py): Browser automation for LinkedIn and complex web scraping

## Key Features

- **Multi-Source Integration**: Collects data from 7+ external APIs and data sources
- **Parallel Data Collection**: Concurrent API calls with configurable timeouts and retry logic
- **Intelligent Error Handling**: Graceful degradation when individual sources fail
- **Performance Optimization**: Configurable execution modes (parallel/sequential) with performance metrics
- **Comprehensive Logging**: Structured logging with source-specific context and performance tracking
- **Rate Limiting**: Built-in rate limiting and respectful API usage patterns

## Data Sources

### Professional Data
- **Apollo.io**: Company enrichment, employee data, contact information, and technology stack
- **LinkedIn**: Company profiles, employee information, recent posts, and professional insights

### Search Intelligence
- **Serper**: Advanced web search results with organic rankings and metadata
- **News Sources**: Google News, Bing News, and specialized news APIs for recent developments

### Employment Data
- **Job Boards**: Seek, Indeed, Glassdoor, LinkedIn Jobs for hiring signals and company culture
- **Career Intelligence**: Job postings analysis for growth indicators and technology adoption

### Official Records
- **Government Registries**: SEC filings, Companies House UK, ASIC Australia, Canadian corporations
- **International Coverage**: European Business Register and multiple jurisdiction support

### Web Intelligence
- **Browser Automation**: Playwright-driven data collection for complex authentication scenarios
- **Content Extraction**: Firecrawl integration for structured web content analysis

## Data Collection Process

1. **Source Configuration**: Dynamic source selection based on availability and requirements
2. **Parallel Execution**: Concurrent API calls with intelligent timeout management
3. **Error Recovery**: Individual source failures don't stop the overall collection process
4. **Data Aggregation**: Structured compilation of results with metadata and performance metrics
5. **Quality Assessment**: Data completeness analysis and source reliability scoring

## Data Structure

Each data source returns structured information including:
- **Core Data**: Company information, employee details, financial data
- **Metadata**: Source reliability, data freshness, collection timestamp
- **Performance Metrics**: Response time, success rate, data completeness
- **Error Information**: Detailed error context for debugging and monitoring

## Usage Patterns

- **Manager Interface**: Use `DataSourceManager.collect_all_prospect_data()` for comprehensive collection
- **Individual Sources**: Access specific data sources for targeted information gathering
- **Async Operations**: All data collection uses async/await for optimal performance
- **Configuration**: Environment-based API key management and source enablement

## Performance Characteristics

- **Parallel Collection**: Typically completes in 10-30 seconds for all sources
- **Timeout Management**: Configurable per-source timeouts (default: 30 seconds)
- **Error Resilience**: System continues operation even with multiple source failures
- **Memory Efficiency**: Streaming data processing with controlled memory usage

## Dependencies

- httpx for async HTTP client operations
- playwright for browser automation
- firecrawl-py for structured web scraping
- structlog for comprehensive logging
- asyncio for concurrent operations
- Python 3.11+ for modern async features

## API Integration

The library integrates with:
- Apollo.io API for B2B company data
- Serper API for search intelligence
- Firecrawl API for web content extraction
- Multiple government registry APIs
- Job board APIs (where available)
- News and media APIs

## Error Handling

- **Source-Level Errors**: Individual source failures are logged and don't affect other sources
- **API Rate Limiting**: Automatic retry with exponential backoff
- **Network Issues**: Timeout handling and graceful degradation
- **Data Validation**: Schema validation for API responses
- **Comprehensive Logging**: Detailed error context for debugging and monitoring
